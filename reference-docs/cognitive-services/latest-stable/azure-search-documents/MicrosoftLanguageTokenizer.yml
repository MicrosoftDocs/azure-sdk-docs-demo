name: MicrosoftLanguageTokenizer
uid: '@azure/search-documents.MicrosoftLanguageTokenizer|latest-stable'
package: '@azure/search-documents|latest-stable'
summary: Divides text using language-specific rules.
fullName: MicrosoftLanguageTokenizer
remarks: ''
isPreview: false
isDeprecated: false
syntax: >-
  type MicrosoftLanguageTokenizer = BaseLexicalTokenizer & { isSearchTokenizer:
  boolean, language: MicrosoftTokenizerLanguage, maxTokenLength: number,
  odatatype: #Microsoft.Azure.Search.MicrosoftLanguageTokenizer }
